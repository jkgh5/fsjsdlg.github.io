WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.765
We're going to walk through an example of joining two separate DataFrames.

00:00:04.765 --> 00:00:07.480
The first thing I'm going to do is check the status

00:00:07.480 --> 00:00:10.110
of Kafka and make sure that it's up and running.

00:00:10.110 --> 00:00:12.990
I going to type PS dash EF.

00:00:12.990 --> 00:00:19.600
When I type that actually the Kafka output started stomping over the top of my terminal.

00:00:19.600 --> 00:00:21.940
I have a pretty good clue that Kafka is running,

00:00:21.940 --> 00:00:25.430
but just to be sure I'm going to go to a different terminal.

00:00:25.430 --> 00:00:31.090
I'm going to clear this to make it easier to read and I'm going to type PS dash EF.

00:00:31.090 --> 00:00:36.380
I do see several Java processes which in this workspace tells me Kafka is running.

00:00:36.380 --> 00:00:40.750
The other thing I notice is I have two processes that are running Spark,

00:00:40.750 --> 00:00:44.740
which tells me that the master and the worker are both active.

00:00:44.740 --> 00:00:49.825
That means I can start coding and be confident I'll be able to submit4 my application.

00:00:49.825 --> 00:00:55.355
In this example, we're going to be bringing in two different messages.

00:00:55.355 --> 00:00:58.325
The first message looks like this,

00:00:58.325 --> 00:01:01.675
and the second message looks like this.

00:01:01.675 --> 00:01:04.890
The first one is the vehicle status.

00:01:04.890 --> 00:01:06.530
It gives the truck number,

00:01:06.530 --> 00:01:10.030
it gives the destination the miles from the shop It's going to,

00:01:10.030 --> 00:01:11.455
and the odometer reading.

00:01:11.455 --> 00:01:14.985
The second one is the vehicle check-in

00:01:14.985 --> 00:01:19.490
and that tells us if the vehicle has been checked in or not.

00:01:19.490 --> 00:01:22.235
It includes a reservation ID,

00:01:22.235 --> 00:01:24.900
a location name, and a truck number.

00:01:24.900 --> 00:01:27.400
You can start thinking of how we could be joining

00:01:27.400 --> 00:01:30.580
these two when we get a little further down.

00:01:30.580 --> 00:01:32.665
Before we get to that point,

00:01:32.665 --> 00:01:35.544
we need to create schemas for both of these payloads.

00:01:35.544 --> 00:01:41.215
The first schema that I'm going to create will be called vehicle status schema.

00:01:41.215 --> 00:01:43.555
It will be a StructType.

00:01:43.555 --> 00:01:45.610
In order to create a StructType,

00:01:45.610 --> 00:01:49.090
I need to pass an array of struct fields.

00:01:49.090 --> 00:01:54.370
The struct fields are all instantiated with a string and a type.

00:01:54.370 --> 00:01:57.235
The string needs to match the JSON string name,

00:01:57.235 --> 00:01:59.290
the JSON field name.

00:01:59.290 --> 00:02:05.455
In this case it's going to be truck number and the type has quotes around it,

00:02:05.455 --> 00:02:07.220
which means it's a string.

00:02:07.220 --> 00:02:10.290
I'm just going to keep going through all the JSON fields.

00:02:10.290 --> 00:02:12.380
The next one is destination,

00:02:12.380 --> 00:02:14.315
and it's a string as well.

00:02:14.315 --> 00:02:16.760
The next one is miles from shop.

00:02:16.760 --> 00:02:21.125
It doesn't have a string quotes around it and it looks like a number,

00:02:21.125 --> 00:02:23.195
and because it's not a decimal,

00:02:23.195 --> 00:02:24.980
I'm going to call it an integer.

00:02:24.980 --> 00:02:26.810
I haven't imported integer,

00:02:26.810 --> 00:02:30.185
so I'm going to make sure to do that here before I use it.

00:02:30.185 --> 00:02:33.550
The next field is odometer reading,

00:02:33.550 --> 00:02:36.855
and it looks like an integer as well.

00:02:36.855 --> 00:02:40.295
I'm going to get rid of my extra lines here, Now,

00:02:40.295 --> 00:02:42.290
I'm going to create a schema for

00:02:42.290 --> 00:02:47.100
the next message type I'm going to call it vehicleCheckinSchema.

00:02:48.050 --> 00:02:50.790
I'm going to follow the same process.

00:02:50.790 --> 00:02:53.240
Why don't you look ahead and see if you can figure

00:02:53.240 --> 00:02:56.299
out what the types are going to be for each of the fields.

00:02:56.299 --> 00:03:00.065
The first struct field will be called reservation ID.

00:03:00.065 --> 00:03:02.315
Have you figured out what type it should be at?

00:03:02.315 --> 00:03:05.360
It has quotes, so that means it should be a string.

00:03:05.360 --> 00:03:11.460
The next one will be called location name and what should that be, What type?

00:03:11.460 --> 00:03:13.690
String type as well.

00:03:13.690 --> 00:03:16.550
The next one is a truck number.

00:03:16.550 --> 00:03:19.805
It could be tricky because it has the name number in it.

00:03:19.805 --> 00:03:22.690
But we notice it has quote symbols around it.

00:03:22.690 --> 00:03:25.085
We're going to make it a string type.

00:03:25.085 --> 00:03:28.565
It turns out all of these fields are strings.

00:03:28.565 --> 00:03:31.870
I was missing some parentheses here.

00:03:31.870 --> 00:03:34.610
Now, I need to read some data from Kafka,

00:03:34.610 --> 00:03:37.010
I have something to actually work with.

00:03:37.010 --> 00:03:39.470
Let's create our spark session.

00:03:39.470 --> 00:03:48.750
I'm going to name this the vehicle check-in application and I'm going to create it.

00:03:48.750 --> 00:03:51.555
I'm going to set the log level.

00:03:51.555 --> 00:03:54.275
Before I figured out I could set the log level,

00:03:54.275 --> 00:03:56.855
it was really hard to find things.

00:03:56.855 --> 00:04:01.595
Now, I'm going to read the vehicleStatus DataFrame.

00:04:01.595 --> 00:04:04.985
That's the first one up here.

00:04:04.985 --> 00:04:08.135
Let's give that a name, Raw,

00:04:08.135 --> 00:04:11.480
because it's coming directly from Kafka.

00:04:11.480 --> 00:04:16.160
We want the read string, not the write string because we're reading not writing.

00:04:16.160 --> 00:04:19.295
We want the Kafka format.

00:04:19.295 --> 00:04:25.480
We've got to set the bootstrap servers

00:04:25.480 --> 00:04:29.944
and we're going to subscribe to the topic called vehicle status.

00:04:29.944 --> 00:04:33.980
This is a predefined topic that has data going to it already.

00:04:33.980 --> 00:04:37.990
You can't just make up a topic and have it have data that doesn't work.

00:04:37.990 --> 00:04:40.860
We need to go to the one that we're looking for.

00:04:40.860 --> 00:04:43.400
If we have a type on that topic name,

00:04:43.400 --> 00:04:46.495
it probably won't get us any data.

00:04:46.495 --> 00:04:50.580
We want the earliest data possible from the topic.

00:04:50.580 --> 00:04:57.660
We're going to tell it the starting offset of earliest and we're going to get it loading.

00:04:58.130 --> 00:05:06.620
I'm going to use the select DX PR to convert this from binary to string.

00:05:07.700 --> 00:05:16.635
I'm going to name it something new and the key for this is the truck ID.

00:05:16.635 --> 00:05:18.405
Just double checking.

00:05:18.405 --> 00:05:20.490
It's called truck number.

00:05:20.490 --> 00:05:27.745
Let's call it that and then what else do we need to cast the value?

00:05:27.745 --> 00:05:32.890
Let's call that the vehicleStatusJson,

00:05:32.990 --> 00:05:35.985
because that's what it has in it.

00:05:35.985 --> 00:05:41.295
Now, let's use that nifty schema we created.

00:05:41.295 --> 00:05:45.260
We're going to call the dot with column method and we're going to overwrite

00:05:45.260 --> 00:05:54.425
the vehicle status Jsonfield using the from JSON method or from JSON function.

00:05:54.425 --> 00:05:56.750
We're going to use the schema we created,

00:05:56.750 --> 00:05:59.365
which is called vehicleStatus Schema.

00:05:59.365 --> 00:06:03.245
We've done that and we've passed it into sub-fields,

00:06:03.245 --> 00:06:05.900
and let's select those subfields.

00:06:05.900 --> 00:06:10.565
We're going to select vehicleStatusOn.Star,

00:06:10.565 --> 00:06:12.970
which will include everything,

00:06:12.970 --> 00:06:15.990
and I need to tell it COL,

00:06:15.990 --> 00:06:18.300
so it knows that's a column name.

00:06:18.300 --> 00:06:21.275
Now, I want to create a view out of that.

00:06:21.275 --> 00:06:26.180
We'll call the view vehicle status and now I'm

00:06:26.180 --> 00:06:31.385
going to select from that vehicle status the fields that I'm interested in.

00:06:31.385 --> 00:06:37.325
I'm going to call the DataFrame that I get out of the view,

00:06:37.325 --> 00:06:44.780
vehicleStatuSelectStar DF, and that's because I'm basically selecting everything.

00:06:44.780 --> 00:06:47.540
But I am going to alias some fields.

00:06:47.540 --> 00:06:49.700
I'm going to call truck number,

00:06:49.700 --> 00:06:54.155
status TruckNumber that so that when I do my join later,

00:06:54.155 --> 00:07:00.825
that has a unique name and I'm selecting from the View vehicle status.

00:07:00.825 --> 00:07:03.060
That data is ready to join.

00:07:03.060 --> 00:07:04.910
Now, I've got all the fields I want,

00:07:04.910 --> 00:07:09.865
and then I've got a unique joined fields that I can use in my joint statement.

00:07:09.865 --> 00:07:12.960
Now, we need to read in my other topic.

00:07:12.960 --> 00:07:18.310
I'm going to call it vehicleCheckIn RawStreamingDF.

00:07:18.650 --> 00:07:21.780
I'm going to pass the bootstrap application,

00:07:21.780 --> 00:07:24.960
which is local hosts with port 1992.

00:07:24.960 --> 00:07:29.425
That could be multiple servers appear in a production environment.

00:07:29.425 --> 00:07:35.345
The topic I'm looking for needs to be exact and it's called check dash in.

00:07:35.345 --> 00:07:41.605
I want to get the earliest message possible and everything after that.

00:07:41.605 --> 00:07:45.345
That's what I'm going to do to get that data.

00:07:45.345 --> 00:07:50.435
We need to do the same conversion on this one from two string format.

00:07:50.435 --> 00:07:55.715
The key for this is going to be a truck number as well.

00:07:55.715 --> 00:08:00.065
Actually, I think it might be the reservation ID.

00:08:00.065 --> 00:08:02.540
We'll call it that,

00:08:02.540 --> 00:08:06.770
and then we're going to cast the value as a string and we're

00:08:06.770 --> 00:08:11.370
going to call it vehicleCheckInJson.

00:08:11.840 --> 00:08:16.070
Now, that we've got the JSON isolated in a field,

00:08:16.070 --> 00:08:21.650
we're going to parse that JSON using the schema we created.

00:08:21.650 --> 00:08:25.160
We're going to do it from, sorry,

00:08:25.160 --> 00:08:28.144
the widthcolumn method,

00:08:28.144 --> 00:08:31.550
widthcolumn will create a column

00:08:31.550 --> 00:08:34.580
if it's not there and if it is, it's going to override it.

00:08:34.580 --> 00:08:38.455
The value we want override is called vehicleCheckInJson.

00:08:38.455 --> 00:08:42.275
Right now, it's just a field with a blob of Json.

00:08:42.275 --> 00:08:45.754
It just looks like this.

00:08:45.754 --> 00:08:47.645
The whole field has this,

00:08:47.645 --> 00:08:53.150
all of this data in one field and then we want to make it so it's separated.

00:08:53.150 --> 00:08:57.035
We're going to say replace that field with

00:08:57.035 --> 00:09:04.890
separate fields and pull the data out of that location,

00:09:04.890 --> 00:09:07.535
the field where the data is already.

00:09:07.535 --> 00:09:13.200
We're going to use the schema we created, the vehicleCheckInSchema.

00:09:15.320 --> 00:09:23.690
This will give us, instead of just a column with all of that data in one column as JSON,

00:09:23.690 --> 00:09:25.955
it'll give it as separate subfields.

00:09:25.955 --> 00:09:28.175
I want to select those subfields.

00:09:28.175 --> 00:09:31.760
I'm going to say select column and I'm going to say

00:09:31.760 --> 00:09:37.745
vehicleCheckInJson.Star because it now has a bunch of fields under it.

00:09:37.745 --> 00:09:43.730
I'm going to create a view out of those called vehicleCheckIn.

00:09:43.730 --> 00:09:47.720
I'm going to select from that view,

00:09:47.720 --> 00:09:54.545
I'm going to call this vehicleCheckInSelectStarDF.

00:09:54.545 --> 00:09:58.910
I'm going to use Spark SQL to select the fields I want.

00:09:58.910 --> 00:10:01.520
I'm going to select for reservation ID,

00:10:01.520 --> 00:10:04.430
location name, truck number,

00:10:04.430 --> 00:10:06.920
but we're going to alias this as well as

00:10:06.920 --> 00:10:13.185
checkintruckNumber and then status and we are getting them all from where?

00:10:13.185 --> 00:10:16.845
vehicleCheckIn is the name of our view.

00:10:16.845 --> 00:10:24.100
Now, we're going to join the two on the truck number column.

00:10:24.140 --> 00:10:30.265
We're going to create a new DataFrame called checkIn StatusDataFrame,

00:10:30.265 --> 00:10:33.080
and we're going to start on the left-hand side with

00:10:33.080 --> 00:10:42.420
the vehicleStatusSelect StarDF and we're going to say dot join.

00:10:42.420 --> 00:10:44.535
Now, we're going to say,

00:10:44.535 --> 00:10:50.610
let's join the vehicleCheckIn SelectStarDataFrame.

00:10:50.610 --> 00:10:53.800
The expression we want to join on.

00:10:53.800 --> 00:10:57.435
We're going to do triple quotes around it,

00:10:57.435 --> 00:11:05.300
and we're going to say statusTruckNumber equals checkinTruckNumber.

00:11:05.630 --> 00:11:09.575
That final DataFrame has

00:11:09.575 --> 00:11:16.010
all the fields and it joins it together from two different DataFrames.

00:11:16.010 --> 00:11:22.330
Let's take a look at what that looks like when we stream it to the console.

00:11:22.330 --> 00:11:27.280
We're going to say checkinStatus Dataframe.writestream.outputmode("append"),

00:11:34.310 --> 00:11:37.830
and the format is console.

00:11:37.830 --> 00:11:43.340
Tell it to start and then tell it to await termination.Now,

00:11:43.340 --> 00:11:46.109
we're going to save that file.

00:11:46.520 --> 00:11:49.955
Now, that we've resolved those various issues,

00:11:49.955 --> 00:11:56.860
let's run this Spark application and look at the joint data that we get as a result.

00:11:56.860 --> 00:12:02.950
We have a script already written in the home workspace spark directory.

00:12:02.950 --> 00:12:09.350
I'm going to list folder and I have a submit vehiclecheckinscrimpt.

00:12:09.350 --> 00:12:11.970
I'm going to run that script.

00:12:12.200 --> 00:12:16.970
Now, we've got the application running and we're waiting for the output.

00:12:16.970 --> 00:12:19.790
This can take longer with joints usually.

00:12:19.790 --> 00:12:21.350
It's hard to be patient,

00:12:21.350 --> 00:12:24.650
but it's good to wait until you start seeing batches coming

00:12:24.650 --> 00:12:29.495
through and then you'll know what you're actually getting out of your application.

00:12:29.495 --> 00:12:31.190
After all this work,

00:12:31.190 --> 00:12:35.015
it's worth the wait, and here's batch zero.

00:12:35.015 --> 00:12:39.380
The joined output that we're seeing has the status truck number column,

00:12:39.380 --> 00:12:41.405
the destination, the miles from shop,

00:12:41.405 --> 00:12:44.330
the odometer reading the reservation ID,

00:12:44.330 --> 00:12:48.655
the location name, the check-in truck number, and the status.

00:12:48.655 --> 00:12:52.880
We have this truck number that seeing a lot of mileage lately,

00:12:52.880 --> 00:12:57.005
a lot of reservations for different destinations.

00:12:57.005 --> 00:13:02.485
We're seeing this truck going to Louisiana, Arizona,

00:13:02.485 --> 00:13:09.365
Colorado, Maryland, Tennessee and we're seeing the status then change on the next batch.

00:13:09.365 --> 00:13:11.525
These reservations are coming in,

00:13:11.525 --> 00:13:15.970
so they're getting checked in at different points.

00:13:15.970 --> 00:13:20.450
We see it go in and out and then in again.

00:13:20.450 --> 00:13:24.830
That's the result of the streaming joined that we did and I'm going to

00:13:24.830 --> 00:13:29.580
kill this biasing Control C and that stopped it.

