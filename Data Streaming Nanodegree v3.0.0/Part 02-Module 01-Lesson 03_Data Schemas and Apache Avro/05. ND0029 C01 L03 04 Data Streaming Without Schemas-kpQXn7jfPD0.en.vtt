WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.609
To better understand why data schemas are important,

00:00:02.609 --> 00:00:04.994
let's walk through an example scenario.

00:00:04.995 --> 00:00:08.535
Pretend that we're working together on a data engineering project.

00:00:08.535 --> 00:00:12.975
On this project, we're consuming data from a production web service through Kafka.

00:00:12.974 --> 00:00:17.280
This web service that we're consuming data from has no formally defined schema.

00:00:17.280 --> 00:00:20.609
Let's say we finish developing our data application and deploy it.

00:00:20.609 --> 00:00:23.699
So as you can see, data is flowing through the system successfully.

00:00:23.699 --> 00:00:25.259
A producer is creating data,

00:00:25.260 --> 00:00:26.520
sending it through Kafka,

00:00:26.519 --> 00:00:28.620
and the consumer is consuming the data.

00:00:28.620 --> 00:00:32.329
All is going well for a few weeks until suddenly we

00:00:32.329 --> 00:00:36.079
get a page from our alerting system that our consumer application is down.

00:00:36.079 --> 00:00:39.199
So we log on and start looking at the logs for application.

00:00:39.200 --> 00:00:41.780
We noticed that our logs are filled with errors.

00:00:41.780 --> 00:00:45.170
These errors show that our Kafka consumer is failing to deserialize

00:00:45.170 --> 00:00:49.765
the received data into our application's model. What happened?

00:00:49.765 --> 00:00:54.515
We message our partners on the web server team to see if anything has changed.

00:00:54.515 --> 00:00:56.960
After looking through their code they say, "Well, yeah,

00:00:56.960 --> 00:01:00.950
we restructured the data model on our end because of a requirements change.

00:01:00.950 --> 00:01:05.570
Now there's nothing left for us to do as a data consumer but to drop everything and

00:01:05.569 --> 00:01:07.879
quickly update our application code to handle

00:01:07.879 --> 00:01:10.689
this modeling change from the upstream application."

00:01:10.689 --> 00:01:13.459
This is a high pressure and costly endeavor and

00:01:13.459 --> 00:01:17.299
not a situation we really want to repeat or find ourselves in ever again.

00:01:17.299 --> 00:01:19.355
What could we have done differently?

00:01:19.355 --> 00:01:21.200
If we'd worked with our colleagues in

00:01:21.200 --> 00:01:24.200
the web server team and asked them to define a schema,

00:01:24.200 --> 00:01:26.240
we would have had a more formalized agreement

00:01:26.239 --> 00:01:28.324
as to what the data should have looked like.

00:01:28.325 --> 00:01:30.980
This schema would have updated when the data changed

00:01:30.980 --> 00:01:33.715
helping our application stay resilient to the update.

00:01:33.715 --> 00:01:37.534
This means that not only would our application have continued to stay online,

00:01:37.534 --> 00:01:41.134
it would have been able to process the newly formatted messages.

00:01:41.135 --> 00:01:44.585
Some schema definition languages can even indicate backwards,

00:01:44.584 --> 00:01:48.559
forwards, or fully compatible changes as you'll see in the upcoming lessons.

00:01:48.560 --> 00:01:50.840
So we can see the breaking change down here.

00:01:50.840 --> 00:01:55.385
Say that the update happened at message 3,002 that broke our consumer.

00:01:55.385 --> 00:01:58.385
We expect an ID and a name.

00:01:58.385 --> 00:02:02.469
That's what the consumer application was receiving up to the message 3,001,

00:02:02.469 --> 00:02:04.319
but at message 3,002,

00:02:04.319 --> 00:02:07.579
the producer team or the web server team updated their format to

00:02:07.579 --> 00:02:10.969
drop the ID and rename the name column to the first name.

00:02:10.969 --> 00:02:13.460
Our consumer application when it tries to unpack

00:02:13.460 --> 00:02:16.890
this data doesn't know how to handle it and crashes.

