WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.540
Let's quickly review some real-world use cases of data schemas.

00:00:03.540 --> 00:00:05.519
More than likely, you've already been using

00:00:05.519 --> 00:00:08.039
data schemas without necessarily realizing it.

00:00:08.039 --> 00:00:13.889
First, think about defining a SQL table in your favorite database like MySQL or Postgres.

00:00:13.890 --> 00:00:16.949
When you declare a table, you always tell the database what

00:00:16.949 --> 00:00:20.384
columns it should have and what the data types are for those columns.

00:00:20.385 --> 00:00:24.340
In this example, I put a Postgres create table statement here,

00:00:24.339 --> 00:00:29.204
and I'm creating a store location table that includes an ID of type integer,

00:00:29.204 --> 00:00:31.139
a name and a city of type var char,

00:00:31.140 --> 00:00:34.664
and a location latitude and longitude of type numeric.

00:00:34.664 --> 00:00:37.979
We need to find a database table in a manner like this.

00:00:37.979 --> 00:00:41.049
You're telling the database what data to expect,

00:00:41.049 --> 00:00:42.750
what shape it will take,

00:00:42.750 --> 00:00:46.520
and what the possible types of the accepted values are for each column.

00:00:46.520 --> 00:00:49.820
This is a very common scenario of schema usage.

00:00:49.820 --> 00:00:52.420
This is what you would end up with.

00:00:52.420 --> 00:00:54.745
Outside of SQL databases,

00:00:54.744 --> 00:00:56.750
if you've ever worked with tools such as Hadoop,

00:00:56.750 --> 00:01:01.369
Hive or Presto, you've likely seen Apache Avro used to describe data.

00:01:01.369 --> 00:01:04.774
For example, Presto can talk to many other data sources,

00:01:04.775 --> 00:01:07.700
some are traditional databases like Postgres,

00:01:07.700 --> 00:01:11.674
and others are simple Cloud-based key-value stores like Amazon's S3.

00:01:11.674 --> 00:01:16.325
For Presto to allow users to run queries across these very different data sources,

00:01:16.325 --> 00:01:19.400
it has to have some idea of what the data looks like.

00:01:19.400 --> 00:01:22.880
Data engineers can write Avro schemas to tell Presto what to

00:01:22.879 --> 00:01:27.019
expect when it fetches data from data sources like Amazon S3.

00:01:27.019 --> 00:01:29.364
If the data is stored in the Avro format,

00:01:29.364 --> 00:01:33.319
presto will know how to load the data and what data types to expect.

00:01:33.319 --> 00:01:37.069
As you can see here, HIVE is talking to this data store which has

00:01:37.069 --> 00:01:40.429
not just only data but also an average schema to go

00:01:40.430 --> 00:01:43.910
along with it and then when that data is returned to Hive,

00:01:43.909 --> 00:01:45.269
it not only gets the data,

00:01:45.269 --> 00:01:46.969
it also receives the schema,

00:01:46.969 --> 00:01:51.724
and it's then able to take that data and transform it into a usable payload.

00:01:51.724 --> 00:01:55.089
Schemas are also used in traditional back-end development.

00:01:55.090 --> 00:01:58.760
The container orchestration platform Kubernetes relies heavily on

00:01:58.760 --> 00:02:02.675
a tool called gRPC to facilitate communication between components.

00:02:02.674 --> 00:02:05.719
gRPC is a communication protocol built

00:02:05.719 --> 00:02:08.870
on Google's protocol buffer schema definition language.

00:02:08.870 --> 00:02:11.550
Using schemas has allowed Kubernetes to bright

00:02:11.550 --> 00:02:13.625
a fast and scalable platform that can

00:02:13.625 --> 00:02:16.685
easily integrate new functionality from third parties.

00:02:16.685 --> 00:02:20.060
Any third-party application can communicate with Kubernetes using

00:02:20.060 --> 00:02:23.545
these predefined schemas and expect for the system to work properly.

00:02:23.544 --> 00:02:27.769
Simply put, Schemas play an important part in today's software ecosystem.

00:02:27.770 --> 00:02:33.060
They can increase speed and clarity of expected data and help reduce mistakes and errors.

