WEBVTT
Kind: captions
Language: zh-CN

00:00:05.179 --> 00:00:08.820
就我的经验来看 学习 Spark 最难的几点之一就是

00:00:08.820 --> 00:00:12.734
函数式编程

00:00:12.734 --> 00:00:14.669
Spark 是

00:00:14.669 --> 00:00:17.625
用 Scala 语言写的

00:00:17.625 --> 00:00:20.190
当你用函数式编程语言编程时

00:00:20.190 --> 00:00:23.160
你处理问题的方式

00:00:23.160 --> 00:00:26.760
有别于使用通用语言 （ Python ） 处理问题

00:00:26.760 --> 00:00:28.935
尽管 Spark 是用 Scala 写的

00:00:28.934 --> 00:00:30.808
但你可以通过其他语言使用它

00:00:30.809 --> 00:00:33.960
比如 Java R  或者 Python

00:00:33.960 --> 00:00:37.280
这节课 你会通过

00:00:37.280 --> 00:00:41.350
Python 的 API （PySpark） 来写程序

00:00:41.350 --> 00:00:44.270
虽然你用的是 PySpark API

00:00:44.270 --> 00:00:48.005
但你还是会其发现其深受 Scala 函数式编程的影响

00:00:48.005 --> 00:00:51.260
比如 在上节课里

00:00:51.259 --> 00:00:53.179
Udith 给你介绍了一个 MapReduce 的问题

00:00:53.179 --> 00:00:56.060
把每首歌的出现次数加总

00:00:56.060 --> 00:00:58.820
这个代码会历遍每行记录

00:00:58.820 --> 00:01:02.000
然后剥离出由歌名和数字 1 组成的元组

00:01:02.000 --> 00:01:04.069
这些元组会被洗牌 

00:01:04.069 --> 00:01:07.699
然后相同歌名的数字 1 会被加总 最后得到歌名和加总结果的元组

00:01:07.700 --> 00:01:12.528
如果你习惯用For Loops计算 你或许会觉得这种计算逻辑有点奇怪

00:01:12.528 --> 00:01:16.084
因为 Spark 使用函数式编程来汇总歌曲出现的次数

00:01:16.084 --> 00:01:19.789
而大多数 Python 程序员们更加熟悉过程化编程

00:01:19.790 --> 00:01:24.170
通过新建一个变量持续记录每首歌出现的次数

00:01:24.170 --> 00:01:27.155
历遍所有歌曲

00:01:27.155 --> 00:01:30.775
如果歌曲匹配 那就给变量加一

00:01:30.775 --> 00:01:33.195
如果你希望高效的使用 Spark

00:01:33.194 --> 00:01:35.629
除了使用程序化编程外

00:01:35.629 --> 00:01:39.869
你还要学会函数式编程的一些工具

