WEBVTT
Kind: captions
Language: zh-CN

00:00:04.490 --> 00:00:08.490
在之前的几节课里 我们介绍了如何处理数据

00:00:08.490 --> 00:00:11.565
包括两种方式 Python 和 SQL

00:00:11.564 --> 00:00:15.299
你可能会纠结使用哪种方式

00:00:15.300 --> 00:00:18.300
你在这些高级 API 中编写的代码

00:00:18.300 --> 00:00:21.150
会先经过查询优化器转换成

00:00:21.149 --> 00:00:24.419
实际的执行计划 然后才开始跑

00:00:24.420 --> 00:00:27.570
Spark 的优化器被称为 catalyst

00:00:27.570 --> 00:00:31.850
catalyst 会将代码转换为相同的 DAG

00:00:31.850 --> 00:00:34.745
所以不管你用 SQL 还是 pySpark

00:00:34.744 --> 00:00:39.689
都不会有大的区别

00:00:40.119 --> 00:00:43.789
基于执行计划生成的代码

00:00:43.789 --> 00:00:46.490
在较底层的数据抽象上运行

00:00:46.490 --> 00:00:49.750
这个底层数据抽象 叫做 RDD 或弹性分布式数据集

00:00:49.750 --> 00:00:53.000
查看 Spark UI 时 你经常会看到

00:00:53.000 --> 00:00:56.795
缩略词 RDD 以及关于它的方法

00:00:56.795 --> 00:00:59.059
在 Spark 的早期版本中

00:00:59.058 --> 00:01:01.924
RDD 是唯一可用的数据抽象

00:01:01.924 --> 00:01:04.715
开发人员必须使用它进行编程

00:01:04.715 --> 00:01:08.885
在 1.3 版中 Spark 引入了 DataFrame API

00:01:08.885 --> 00:01:10.960
然后在 2.0 版中

00:01:10.959 --> 00:01:14.574
DataFrames 和 DataFrames API 被合并了

00:01:14.575 --> 00:01:17.650
在某些情况下 更高级别的 API 并不能满足我们对

00:01:17.650 --> 00:01:19.850
灵活性的需求

00:01:19.849 --> 00:01:22.574
所以我们需要直接使用 RDD 

00:01:22.575 --> 00:01:25.760
你可能还记得我解释

00:01:25.760 --> 00:01:29.030
命令式和声明性编程之间的区别用到的例子

00:01:29.030 --> 00:01:32.284
我说过 一个命令式语句就好比说

00:01:32.284 --> 00:01:33.530
先上车

00:01:33.530 --> 00:01:36.364
开车两英里到我最喜欢的面包店

00:01:36.364 --> 00:01:39.319
走进商店 从柜台找蛋糕

00:01:39.319 --> 00:01:41.314
买蛋糕 开车回家

00:01:41.314 --> 00:01:43.204
当你处理RDD时

00:01:43.204 --> 00:01:47.719
你要用更详细的命令式语句 例如

00:01:47.719 --> 00:01:52.489
打开车门 坐下 启动发动机等等

00:01:52.489 --> 00:01:58.384
使用 RDD 为我们提供了极大的灵活性 但代码更难读写

00:01:58.385 --> 00:02:01.700
并且由于这种灵活性 我们也无法使用 catalyst 了

00:02:01.700 --> 00:02:05.495
优化代码也变得更加困难

00:02:05.495 --> 00:02:06.965
下一课中

00:02:06.965 --> 00:02:10.640
我们要看看优化 Spark 代码的不同方法

00:02:10.639 --> 00:02:14.649
并将更加详细介绍如何使用 RDD

