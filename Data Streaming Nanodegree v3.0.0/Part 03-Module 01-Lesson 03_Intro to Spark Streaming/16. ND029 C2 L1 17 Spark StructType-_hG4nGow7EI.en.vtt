WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.850
If your code is organized as DataFrame,

00:00:02.850 --> 00:00:05.685
order dependencies can become a big problem.

00:00:05.684 --> 00:00:07.679
Dataset provides type safety,

00:00:07.679 --> 00:00:09.900
but since it's not available in Python,

00:00:09.900 --> 00:00:12.089
we need to enforce schema on data.

00:00:12.089 --> 00:00:14.849
You might need to figure out how to call 20 functions in

00:00:14.849 --> 00:00:17.669
exactly the right order to get the desired result.

00:00:17.670 --> 00:00:22.155
A StructType columns are one way to eliminate order dependencies from your code.

00:00:22.155 --> 00:00:25.859
Let's go through some sample code on how to create schema for your data.

00:00:25.859 --> 00:00:30.195
In this demo, we will see how enforcing schema helps with your data quality.

00:00:30.195 --> 00:00:34.564
We'll also use StructType and struct fields in SQL.types library.

00:00:34.564 --> 00:00:39.250
Here we'll be importing Spark session to create our Spark session.

00:00:39.250 --> 00:00:40.960
As we said before,

00:00:40.960 --> 00:00:43.755
I'll be importing the types library,

00:00:43.755 --> 00:00:45.870
and we'll create a Spark session.

00:00:45.869 --> 00:00:49.489
Let's create a DataFrame that contains

00:00:49.490 --> 00:00:54.815
country name and the cities and population for each city.

00:00:54.814 --> 00:01:00.140
So I'm going to create a three lists countries.

00:01:00.140 --> 00:01:04.109
I'm just going to do two countries for Columbia.

00:01:04.719 --> 00:01:10.700
One is USA, and then cities list,

00:01:10.700 --> 00:01:19.225
which has probably the most populated cities in both countries and New York.

00:01:19.224 --> 00:01:29.959
For population, let's say we have a string value and an integer.

00:01:29.959 --> 00:01:35.239
Now I'm going to create a schema for the DataFrame that I'm going to create.

00:01:35.239 --> 00:01:36.545
So what I can do is,

00:01:36.545 --> 00:01:38.450
create a variable called schema,

00:01:38.450 --> 00:01:42.515
and I'm going to wrap this with StructType.

00:01:42.515 --> 00:01:47.689
StructType is inside of the scaled-up types library.

00:01:47.689 --> 00:01:49.890
I'm going to construct fields,

00:01:49.890 --> 00:01:53.189
countries, cities, and population using StructField.

00:01:53.189 --> 00:01:56.325
Then this will be a string type, and true.

00:01:56.325 --> 00:01:59.460
This means the column could be null-able.

00:01:59.459 --> 00:02:02.704
Next field I'm going to do is the cities,

00:02:02.704 --> 00:02:07.054
string type also, and I can do population.

00:02:07.055 --> 00:02:09.640
Then we want to put it as an integer type.

00:02:09.639 --> 00:02:12.879
Now what I can do is create a DataFrame enforcing

00:02:12.879 --> 00:02:19.000
these schema on top of three different lists.

00:02:19.000 --> 00:02:22.905
I can do zip all three lists.

00:02:22.905 --> 00:02:26.669
In order of countries, cities,

00:02:26.669 --> 00:02:31.239
population, and I'm going to enforce schema using that schema.

00:02:31.240 --> 00:02:39.055
Then you can see that it throws an error where it is expecting value error,

00:02:39.055 --> 00:02:44.760
verify where it's not accepting a certain type.

00:02:45.680 --> 00:02:48.615
The typer says, "The field population,

00:02:48.615 --> 00:02:51.325
integer type cannot accept object."

00:02:51.324 --> 00:02:55.234
Because this was a string value.

00:02:55.235 --> 00:03:00.065
So if I change this value into an integer type,

00:03:00.064 --> 00:03:01.490
for example like this,

00:03:01.490 --> 00:03:03.485
and then do this again,

00:03:03.485 --> 00:03:06.080
this won't run successfully,

00:03:06.080 --> 00:03:08.825
and since there's only two of them, I can do this.

00:03:08.824 --> 00:03:13.414
So creating schema actually enforces on your data quality to have

00:03:13.414 --> 00:03:20.129
a cleaner dataset especially for languages like Python which is not type-safe.

