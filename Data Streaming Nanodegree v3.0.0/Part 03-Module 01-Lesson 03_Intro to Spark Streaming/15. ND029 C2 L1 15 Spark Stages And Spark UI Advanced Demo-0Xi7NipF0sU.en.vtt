WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.194
So with this code we'll take a look at Spark stages.

00:00:03.194 --> 00:00:05.519
Let's go to that Master UI.

00:00:05.519 --> 00:00:07.830
If we click on the Stages tab,

00:00:07.830 --> 00:00:12.509
we'll see Completed Stages which are many reading CSV files,

00:00:12.509 --> 00:00:14.429
show string and collect.

00:00:14.429 --> 00:00:19.199
Let's take a look at a collect at the end

00:00:19.199 --> 00:00:24.674
because reading CSV file will only show a file scan at one point.

00:00:24.675 --> 00:00:29.355
Notice also the duration is much.

00:00:29.355 --> 00:00:31.350
The shortest duration is probably this one.

00:00:31.350 --> 00:00:34.094
So let's take a quick look.

00:00:34.094 --> 00:00:37.244
So you can see a single stage here.

00:00:37.244 --> 00:00:42.314
There was a file scan map partition and then that partition internally.

00:00:42.314 --> 00:00:48.174
In the stages tab you can select on show additional metrics.

00:00:48.174 --> 00:00:52.029
You can take a look at event timelines so it shows like there was

00:00:52.030 --> 00:00:57.850
a scheduler delay and Task Deserialization Time an executor computing time.

00:00:57.850 --> 00:01:00.594
This is what is really important because it

00:01:00.594 --> 00:01:04.179
actually shows how much your executor is taking to compute this.

00:01:04.180 --> 00:01:07.955
Relatively slow, eight millimeters, eight millisecond.

00:01:07.954 --> 00:01:10.334
When you look at this,

00:01:10.334 --> 00:01:15.519
also their information of tasks right now we only have one of these but

00:01:15.519 --> 00:01:21.114
once your partitions and the number of nodes grow you'll see a bunch of these tasks grow.

00:01:21.114 --> 00:01:27.289
So let's take a look at the last collect for detailed stages.

00:01:27.290 --> 00:01:32.840
Here you can see the lineage here: file scan, map partition.

00:01:32.840 --> 00:01:38.240
Even though there are many different types of transformation we applied,

00:01:38.239 --> 00:01:40.640
it will only really show map partition.

00:01:40.640 --> 00:01:44.885
Since we're using the Python it'll just show iPython instead of

00:01:44.885 --> 00:01:49.820
little more detailed information when we're using Scala vs Python,

00:01:49.819 --> 00:01:55.819
but here you can see the input size and the records which is kind of important to know.

00:01:55.819 --> 00:01:58.024
Because when we go back,

00:01:58.025 --> 00:02:04.130
if I do facilities df.count you all get the same number 3,756.

00:02:04.129 --> 00:02:10.564
So this probably shows information about the facility to DF not the tiers DF,

00:02:10.564 --> 00:02:12.919
which is another Data Frame we create in.

00:02:12.919 --> 00:02:18.984
If we do that count here this will be 1475.

00:02:18.985 --> 00:02:22.325
You can say that, let's take a look at this.

00:02:22.324 --> 00:02:25.039
If it was a smaller number of collect.

00:02:25.039 --> 00:02:30.049
Here you can see the input size was in kilobytes which is kind of not

00:02:30.050 --> 00:02:37.805
useful but you can see the record of that being batches with tiers data frame.

00:02:37.805 --> 00:02:40.520
Also these counts are generated by the counts that I've

00:02:40.520 --> 00:02:43.325
just ran and you can see there was input

00:02:43.324 --> 00:02:48.905
there was a shuffle read and then there was a shuffle write because we did an action.

00:02:48.905 --> 00:02:54.419
It does have some kind of write, action wars there.

