WEBVTT
Kind: captions
Language: en

00:00:01.580 --> 00:00:03.734
Before we go any further,

00:00:03.734 --> 00:00:05.969
let's take a moment to compare and contrast

00:00:05.969 --> 00:00:10.184
batch and stream processing so the pros and cons of each approach are more apparent.

00:00:10.185 --> 00:00:15.150
Batch processing involves the periodic analysis unrelated groups of data.

00:00:15.150 --> 00:00:19.335
Historically, this has been how most data engineers analyze data.

00:00:19.335 --> 00:00:22.545
Batch processing remains an important approach from most,

00:00:22.545 --> 00:00:25.304
if not all, data engineering organizations.

00:00:25.304 --> 00:00:28.410
For example, you may write a job that joins or

00:00:28.410 --> 00:00:32.100
aggregates the last hours of the data every hour on the hour.

00:00:32.100 --> 00:00:35.010
The results of this kind of aggregation are typically written to

00:00:35.009 --> 00:00:38.534
a long-term SQL like store for long-term analysis.

00:00:38.534 --> 00:00:44.674
Importantly, customers of that data will only receive updates once an hour on the hour.

00:00:44.674 --> 00:00:48.709
The best resolution of that data will always be one hour,

00:00:48.710 --> 00:00:52.660
that's because the batch only runs once an hour.

00:00:52.659 --> 00:00:57.679
Additionally, batch processing jobs typically work against multiple data stores,

00:00:57.679 --> 00:00:59.479
so records may be added, deleted,

00:00:59.479 --> 00:01:02.344
or modified between runs.

00:01:02.344 --> 00:01:06.575
Again, the datastores they're using are also typically mutable.

00:01:06.575 --> 00:01:10.984
The advantage of this approach however is that the analysis maybe it'll take advantage of

00:01:10.984 --> 00:01:13.429
all the available data in the system and run

00:01:13.430 --> 00:01:16.595
for longer periods of time than a stream processing pipeline.

00:01:16.594 --> 00:01:19.655
With the advent of cheap commodity cloud computing

00:01:19.655 --> 00:01:22.265
and the wide availability of inexpensive storage,

00:01:22.265 --> 00:01:25.400
newer solutions such as stream processing have become feasible,

00:01:25.400 --> 00:01:29.645
and sometimes even required to provide faster insight into our systems.

00:01:29.644 --> 00:01:31.879
In contrast a batch processing,

00:01:31.879 --> 00:01:36.004
stream processing runs every single time a new event is generated.

00:01:36.004 --> 00:01:39.875
There is no fixed schedule for stream processing applications.

00:01:39.875 --> 00:01:43.204
This means that the output of your stream processing pipeline is

00:01:43.204 --> 00:01:46.879
likely as up-to-date as the latest event generated by your system.

00:01:46.879 --> 00:01:51.019
A data consumed by stream processing applications is typically

00:01:51.019 --> 00:01:52.909
immutable and can assume that

00:01:52.909 --> 00:01:57.094
individual events will not be modified or deleted between runs.

00:01:57.094 --> 00:02:00.049
Stream processing applications may themselves simply produce

00:02:00.049 --> 00:02:03.424
more events rather than running to a longer-term datastore.

00:02:03.424 --> 00:02:08.030
However, a disadvantage to this approach is that data may be so large

00:02:08.030 --> 00:02:09.979
the stream processing system may not have

00:02:09.979 --> 00:02:13.399
the context of all the data that has ever passed through the system.

00:02:13.400 --> 00:02:15.120
That's not always the case,

00:02:15.120 --> 00:02:17.090
but this means that while this data may be excellent

00:02:17.090 --> 00:02:19.550
for trends over short windows of time,

00:02:19.550 --> 00:02:22.430
it may not give us a full historical picture.

00:02:22.430 --> 00:02:25.370
I think it's important to note that the differences we've

00:02:25.370 --> 00:02:28.145
laid out here are generalizations, they're not hard rules.

00:02:28.145 --> 00:02:31.450
There are batch jobs that will only look at limited subsets of data,

00:02:31.449 --> 00:02:35.494
and there are stream processing jobs that can analyze all the data available on a system.

00:02:35.495 --> 00:02:38.675
These scenarios are the exception not the rule however.

00:02:38.675 --> 00:02:42.564
Finally, batch and stream processing are not mutually exclusive,

00:02:42.564 --> 00:02:44.060
just want to reiterate this.

00:02:44.060 --> 00:02:46.069
Just because you're using stream processing

00:02:46.069 --> 00:02:48.604
doesn't mean that batch processing is no longer relevant.

00:02:48.604 --> 00:02:52.864
The two types of processing approaches work really really well together, and in fact,

00:02:52.865 --> 00:02:55.570
I recommend that you don't abandon batch processing,

00:02:55.569 --> 00:02:58.969
stream processing compliments your batch processing jobs.

00:02:58.969 --> 00:03:02.810
Batch systems can create events to feed industry and processing applications,

00:03:02.810 --> 00:03:08.550
and similarly, stream processing applications can be part of batch processing analysis.

