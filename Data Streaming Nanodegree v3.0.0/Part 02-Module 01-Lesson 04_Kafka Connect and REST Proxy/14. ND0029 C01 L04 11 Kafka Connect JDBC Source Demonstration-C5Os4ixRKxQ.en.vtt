WEBVTT
Kind: captions
Language: en

00:00:01.730 --> 00:00:05.490
Now, that you've learned what a JDBC connector is,

00:00:05.490 --> 00:00:07.169
we're going to actually build one.

00:00:07.169 --> 00:00:10.169
Let's build a JDBC source connector that loads

00:00:10.169 --> 00:00:13.365
data from the Postgres purchase table into Kafka.

00:00:13.365 --> 00:00:16.710
We're going to return to our workspace once again and we're

00:00:16.710 --> 00:00:19.964
going to take a quick look at the sample3.py file which I've loaded up.

00:00:19.964 --> 00:00:22.394
So we're going to go back to single document mode

00:00:22.394 --> 00:00:25.359
and the first thing you're going to notice is that we have the same URL,

00:00:25.359 --> 00:00:27.789
we have a slightly different connector name,

00:00:27.789 --> 00:00:32.179
but we're going to now be creating a JDBC connector,

00:00:32.179 --> 00:00:35.375
which has a different format from the file source connector.

00:00:35.375 --> 00:00:38.645
I've already pre-loaded the documentations, let's pop, that open.

00:00:38.645 --> 00:00:44.010
So there are many more options for the JDBC source connector,

00:00:44.009 --> 00:00:45.199
as well as the sync connector.

00:00:45.200 --> 00:00:47.915
Now, we're not going to be able to cover all of them,

00:00:47.914 --> 00:00:50.004
but I do want to bring up this documentation,

00:00:50.005 --> 00:00:53.255
this is going to be linked in your exercise for you to reference as well.

00:00:53.255 --> 00:00:56.855
But it's important to have a read through here at to try to get a feel and understand

00:00:56.854 --> 00:01:02.224
what options are actually available to you as a user of the JDBC source connector,

00:01:02.225 --> 00:01:04.420
there are some things that you have to provide,

00:01:04.420 --> 00:01:06.314
which we're going to review you shortly.

00:01:06.314 --> 00:01:08.310
First, just like every connector,

00:01:08.310 --> 00:01:10.920
you have to tell the KAFKA_CONNET which connector class to

00:01:10.920 --> 00:01:14.605
use and specifically for the JDBC source connector,

00:01:14.605 --> 00:01:17.240
what the prefix for the topics should be when it loads

00:01:17.239 --> 00:01:20.539
the data out of your database into Kafka.

00:01:20.540 --> 00:01:24.920
But you also have to give it some information such as which tables you are interested in,

00:01:24.920 --> 00:01:27.320
If you don't give it this information it will load every table

00:01:27.319 --> 00:01:30.184
in your database into Kafka connect.

00:01:30.185 --> 00:01:34.715
Additionally, KAFKA_CONNECT will actually monitor your database for changes,

00:01:34.715 --> 00:01:38.600
so as incrementing column name tells Kafka for the for

00:01:38.599 --> 00:01:42.439
the tables that is loading which column it should look for for updates,

00:01:42.439 --> 00:01:44.254
so let's go ahead and start to fill this out.

00:01:44.254 --> 00:01:47.324
The first thing we need to do is figure out what the connector class is.

00:01:47.325 --> 00:01:50.945
So let's go back to the documentation and will scroll up,

00:01:50.944 --> 00:01:54.099
scroll up and we can see that that's the first thing documented on a page,

00:01:54.099 --> 00:01:58.224
connector class is io.confluent.connect.jdbc.

00:01:58.224 --> 00:02:01.274
jdbcSourceConnector, Let's go ahead and fill it.

00:02:01.275 --> 00:02:03.995
Now, the next thing is a topic prefix.

00:02:03.995 --> 00:02:07.460
So we're loading the purchases table out of our SQL database,

00:02:07.459 --> 00:02:12.245
so let's go ahead and just prefix it with connect dash,

00:02:12.245 --> 00:02:16.045
so we know that KAFKA_CONNECT created the database table.

00:02:16.044 --> 00:02:19.594
Next, let's go ahead and give it a maximum number of tasks,

00:02:19.594 --> 00:02:22.520
again we're going to do one just like the previous example.

00:02:22.520 --> 00:02:24.500
Now, the next thing is mode.

00:02:24.500 --> 00:02:30.669
Now, this says to KAFKA_CONNECT what mode for the JDBC source connector run in,

00:02:30.669 --> 00:02:35.119
some of the options here include bulk or incrementing,

00:02:35.120 --> 00:02:39.200
but let's actually take a look to see what the options are in the documentation.

00:02:39.199 --> 00:02:42.259
You can see they have nice documentation on it.

00:02:42.259 --> 00:02:46.590
This essentially says, bulk says every time KAFKA_CONNECT loads,

00:02:46.590 --> 00:02:47.990
it just takes all the data in

00:02:47.990 --> 00:02:51.020
the table regardless of whether or not it's already seen it,

00:02:51.020 --> 00:02:55.530
incrementing means it will actually use a column in the database table,

00:02:55.530 --> 00:02:57.710
to identify whether or not data has changed,

00:02:57.710 --> 00:03:02.120
and if data has changed it will load the data into Kafka once again.

00:03:02.120 --> 00:03:06.710
Timestamp uses an actual timestamp column to detect changes and

00:03:06.710 --> 00:03:09.200
timestamp and incrementing will use a combination of

00:03:09.199 --> 00:03:11.974
both an incrementing column and a timestamp,

00:03:11.974 --> 00:03:14.599
this is most popular in most used cases.

00:03:14.599 --> 00:03:16.384
For us today, we're just going to use

00:03:16.384 --> 00:03:19.174
incrementing because we have an incrementing column.

00:03:19.175 --> 00:03:21.484
So we're going to return back to our workspace,

00:03:21.484 --> 00:03:24.260
set the mode to incrementing and then we

00:03:24.259 --> 00:03:27.334
have to tell it what the incrementing column name is.

00:03:27.335 --> 00:03:31.205
At this point is probably a good idea to actually take a look at our database.

00:03:31.205 --> 00:03:36.605
So let's actually open up a new terminal and drop out of single document mode.

00:03:36.604 --> 00:03:39.889
I'm going to use psql to connect to Postgres,

00:03:39.889 --> 00:03:42.474
the name of our database is classroom.

00:03:42.474 --> 00:03:45.250
Now, that I'm connected, I'm going to describe

00:03:45.250 --> 00:03:49.990
the purchases table and I make this full screen so we can actually look at it.

00:03:49.990 --> 00:03:52.960
So the command I've used here is backslash d,

00:03:52.960 --> 00:03:57.099
which essentially tells psql that I wanted to describe the purchases table,

00:03:57.099 --> 00:03:59.889
so I can see the columns and the type.

00:03:59.889 --> 00:04:01.943
So we can see we have a username,

00:04:01.943 --> 00:04:03.879
a currency in amount, to var char,

00:04:03.879 --> 00:04:08.210
there is an integer, and we also have an id column called id.

00:04:08.210 --> 00:04:11.905
The id column will uniquely identify every single purchase.

00:04:11.905 --> 00:04:14.649
So we're going to want to use this as our incrementing column,

00:04:14.649 --> 00:04:16.944
as purchases are added to the purchases table,

00:04:16.944 --> 00:04:20.339
we'll see this id numbers take up.

00:04:20.339 --> 00:04:23.664
It's going to jump out of the single document mode,

00:04:23.665 --> 00:04:27.540
we're going to set this incrementing column name

00:04:27.540 --> 00:04:29.689
to id and if you want more information on this,

00:04:29.689 --> 00:04:35.040
you can look in the documentation over here and see documented here.

00:04:35.899 --> 00:04:38.824
Then we're going to give it a table whitelist,

00:04:38.824 --> 00:04:43.310
now you can both blacklist and whitelist tables. What does that mean?

00:04:43.310 --> 00:04:47.360
This tells KAFKA_CONNECT, a whitelist says I only want you to look at

00:04:47.360 --> 00:04:49.879
these tables and a blacklist says I want you to look at

00:04:49.879 --> 00:04:52.894
all tables but the ones that are listed.

00:04:52.894 --> 00:04:56.689
Well, in this case, I only want KAFKA_CONNECT to look at a single table,

00:04:56.689 --> 00:04:59.295
so I'm going to tell it purchase,

00:04:59.295 --> 00:05:00.900
because we only are purchases,

00:05:00.899 --> 00:05:03.149
because we're looking at public.purchases.

00:05:03.149 --> 00:05:05.644
All right. Now, I've already pre-filled

00:05:05.644 --> 00:05:08.284
a couple of other options here, the connection URL,

00:05:08.285 --> 00:05:12.345
which has a JDBC connection URL for postgresql on

00:05:12.345 --> 00:05:19.745
a local machine to the classroom database and I've specified the database user as root.

00:05:19.745 --> 00:05:22.865
With that done, we're ready to go.

00:05:22.865 --> 00:05:30.095
So I'm going to exit out the SQL and I'm going to run sample three. All right.

00:05:30.095 --> 00:05:32.075
Now, let's actually curl KAFKA_CONNECT,

00:05:32.074 --> 00:05:34.745
to make sure that it's actually seen this request.

00:05:34.745 --> 00:05:40.259
So again we're going to hit the connectors URL to see that our connector is present.

00:05:42.850 --> 00:05:45.350
So we have sample two and now we have

00:05:45.350 --> 00:05:50.705
purchases JDBC and let's get the status of purchases JDBC,

00:05:50.704 --> 00:05:54.240
just to make sure that it's actually running.

00:05:56.180 --> 00:05:59.949
So if we go back into full view,

00:05:59.949 --> 00:06:06.899
we can see that the purchases JDBC connector is in the running state as is its task.

