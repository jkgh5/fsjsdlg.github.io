WEBVTT
Kind: captions
Language: zh-CN

00:00:06.480 --> 00:00:09.685
当你打开程序的输出文件时

00:00:09.685 --> 00:00:11.935
你会看到好几百行的数据

00:00:11.935 --> 00:00:14.470
但你的预期是会看到几百万行

00:00:14.470 --> 00:00:17.109
似乎这个程序工作了一小会儿

00:00:17.109 --> 00:00:18.715
然后突然卡住了

00:00:18.714 --> 00:00:20.969
为了调试你的程序

00:00:20.969 --> 00:00:22.699
你又跑了一次程序

00:00:22.699 --> 00:00:25.960
这次你把其他无关的程序都关了

00:00:25.960 --> 00:00:29.545
除了你的系统管理器

00:00:29.545 --> 00:00:31.840
当你开始跑程序时

00:00:31.839 --> 00:00:35.530
存储内存和CPU活动一下子就增加一些

00:00:35.530 --> 00:00:37.960
因为第一部分的数据

00:00:37.960 --> 00:00:40.299
从存储加载到了内存

00:00:40.299 --> 00:00:42.769
然后被CPU 处理了

00:00:42.770 --> 00:00:46.815
这之后 CPU 的活动就减落了

00:00:46.814 --> 00:00:49.609
但是内存和存储的输入/输出或者叫 IO 

00:00:49.609 --> 00:00:53.134
增加到了接近百分之百

00:00:53.134 --> 00:00:56.089
CPU 活动偶尔会小跳一下

00:00:56.090 --> 00:00:58.000
显然你系统的存储和内存

00:00:58.000 --> 00:01:01.375
正在拖慢CPU

00:01:01.375 --> 00:01:04.090
这是你电脑里的活动的过程

00:01:04.090 --> 00:01:07.750
程序从存储加载了大概8 G 的数据到内存

00:01:07.750 --> 00:01:11.575
导致其他程序和系统没有内存使用了

00:01:11.575 --> 00:01:15.159
你的CPU处理数据非常快

00:01:15.159 --> 00:01:17.649
迅速把结果返回给内存

00:01:17.650 --> 00:01:20.665
然后被写入硬盘的输出文件里

00:01:20.665 --> 00:01:22.390
这和数据量只有4 G时

00:01:22.390 --> 00:01:24.709
发生的事一样

00:01:24.709 --> 00:01:28.989
但是当第一批差不多 8 G 的数据被 CPU 处理好后

00:01:28.989 --> 00:01:31.009
它就开始准备处理下批数据了

00:01:31.010 --> 00:01:33.890
这时 CPU的活动下降了很多

00:01:33.890 --> 00:01:38.194
但是下一批数据还有没有准备好

00:01:38.194 --> 00:01:41.229
它需要从硬盘加载到内存

00:01:41.230 --> 00:01:42.995
这非常慢

00:01:42.995 --> 00:01:46.250
回忆一下 从硬盘加载数据

00:01:46.250 --> 00:01:49.900
会比CPU处理数据慢3000 多倍

00:01:49.900 --> 00:01:52.130
而且要经过好几十次这样的过程

00:01:52.129 --> 00:01:55.414
才能把 200 G 的数据处理完

00:01:55.415 --> 00:01:58.685
这就是你系统卡住的原因

00:01:58.685 --> 00:02:03.004
其实就是大部分的时间都被用来搬数据了

00:02:03.004 --> 00:02:07.219
CPU 大部分活动都是在协调搬运数据

00:02:07.219 --> 00:02:10.234
就像你大脑一直在做任务切换

00:02:10.235 --> 00:02:13.730
这个来来回回的过程叫做颠簸

00:02:13.729 --> 00:02:16.989
当数据量很大时这会成为严重的问题

00:02:16.990 --> 00:02:20.659
突然 你想起了你去年的点子

00:02:20.659 --> 00:02:26.254
如果你把数据拆分成多份 然后邮件给同事会快一些吗？

00:02:26.254 --> 00:02:28.840
于是你把数据发给了 40 个同事

00:02:28.840 --> 00:02:31.039
所以每部分数据只有 5 G

00:02:31.039 --> 00:02:32.750
这些数据就可以一下加载到内存里了

00:02:32.750 --> 00:02:35.030
因为不存在颠簸

00:02:35.030 --> 00:02:38.300
同事们很快就跑出了结果 然后把结果发还给你了

00:02:38.300 --> 00:02:42.415
虽然发 200 G 数据的邮件要花很长时间

00:02:42.414 --> 00:02:44.304
毕竟网速太慢了

00:02:44.305 --> 00:02:46.909
但是你只用分配一次数据

00:02:46.909 --> 00:02:49.449
这样就完全避免了颠簸问题

00:02:49.449 --> 00:02:52.879
为了避免颠簸 你还可以把数据分成 80 份

00:02:52.879 --> 00:02:56.569
然后给每个同事发两份

00:02:56.569 --> 00:02:59.525
这样 他们就可以先下载第一份

00:02:59.525 --> 00:03:02.740
然后在处理第一份的同时下载第二份数据

00:03:02.740 --> 00:03:05.540
和去年一样 你还是会面临

00:03:05.539 --> 00:03:09.079
Python 版本的兼容 同事分身乏术等问题

00:03:09.080 --> 00:03:12.050
但和死机比起来

00:03:12.050 --> 00:03:16.010
利弊权衡后 这个方法还是值得一试的

00:03:16.009 --> 00:03:19.789
现在 把数据分配到多台电脑

00:03:19.789 --> 00:03:22.084
同时处理数据就优于单台电脑了

00:03:22.085 --> 00:03:25.409
欢迎来到大数据的世界

