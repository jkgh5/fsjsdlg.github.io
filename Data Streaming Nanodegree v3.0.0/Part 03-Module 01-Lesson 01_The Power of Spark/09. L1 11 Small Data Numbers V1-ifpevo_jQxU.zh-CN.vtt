WEBVTT
Kind: captions
Language: zh-CN

00:00:06.620 --> 00:00:09.419
现在我们来讲几个在业界做数据工作时

00:00:09.419 --> 00:00:12.425
经常会遇到的例子

00:00:12.425 --> 00:00:15.795
然后讨论一下我们是否要用到 Spark 这样的工具

00:00:15.794 --> 00:00:19.425
数据处理的前几步就要把数据提取出来

00:00:19.425 --> 00:00:21.890
找到你想要的数据

00:00:21.890 --> 00:00:25.140
假设你在一家叫 Sparkify 的创业公司工作

00:00:25.140 --> 00:00:27.800
这家数字音乐公司提供播放歌曲服务

00:00:27.800 --> 00:00:31.370
用户播放自己喜欢的歌曲 类似于网易云或 QQ 音乐

00:00:31.370 --> 00:00:33.649
为了让 Sparkify 做大做强

00:00:33.649 --> 00:00:37.034
你要理解用户是如何使用你的产品的

00:00:37.034 --> 00:00:40.204
比如 你的内容团队想要搞清楚

00:00:40.204 --> 00:00:43.850
加拿大人听的最多的是谁的歌

00:00:43.850 --> 00:00:48.350
大部分时候 每个国家的内容授权协议都是单独协商的

00:00:48.350 --> 00:00:51.829
知道这个信息可以帮助他们决定和哪个歌手续签合同

00:00:51.829 --> 00:00:55.125
过去一年里 每当有用户听了一首歌

00:00:55.125 --> 00:00:58.799
Sparkify app 都会写记录到一个大的日志文件里

00:00:58.799 --> 00:01:01.649
夜里把日志下载到电脑里

00:01:01.649 --> 00:01:04.704
每个记录都包括一堆字段

00:01:04.704 --> 00:01:07.685
比如 歌名 歌手 时间戳

00:01:07.685 --> 00:01:09.575
以及 用户信息 如 名字

00:01:09.575 --> 00:01:12.299
地区 浏览器信息等

00:01:12.299 --> 00:01:13.789
不一而足

00:01:13.790 --> 00:01:16.220
第一步就是把你需要的那部分信息

00:01:16.219 --> 00:01:19.525
从原始的日志文件中提取出来

00:01:19.525 --> 00:01:23.430
这个例子中 我们只需要知道加拿大用户听过的歌手信息

00:01:23.430 --> 00:01:25.745
所以我们的处理也很简单

00:01:25.745 --> 00:01:28.365
你把非加拿大用户剔除

00:01:28.364 --> 00:01:30.754
然后把歌手相关字段提取出来

00:01:30.754 --> 00:01:33.099
因为 Sparkily 用户不多

00:01:33.099 --> 00:01:35.134
只有几千个

00:01:35.135 --> 00:01:37.370
数据量也不大

00:01:37.370 --> 00:01:39.890
去年一年的数据只有4 G

00:01:39.890 --> 00:01:43.995
一下把所有数据加载到 8 G 的内存里也没问题

00:01:43.995 --> 00:01:48.219
于是你可以把所有的数据按顺序加载到内存里

00:01:48.219 --> 00:01:50.409
你可以写个简单的 Python 程序让

00:01:50.409 --> 00:01:53.424
 CPU 把歌手信息过滤提取出来

00:01:53.424 --> 00:01:55.700
因为你在的初创公司很有冒险精神

00:01:55.700 --> 00:01:57.109
愿意尝试所有事情

00:01:57.109 --> 00:02:01.189
于是你想了想 有没有其他更便捷的方式处理这部分数据

00:02:01.189 --> 00:02:04.179
一个方式就是把数据拆分开

00:02:04.180 --> 00:02:08.540
或许可以把每个月的数据发到不同同事们的电脑里

00:02:08.539 --> 00:02:10.905
让他们跑你的 Python 程序

00:02:10.905 --> 00:02:13.890
然后把结果发还给你

00:02:13.889 --> 00:02:15.814
但是这并不值得

00:02:15.814 --> 00:02:20.444
通过网络来发数据是整个过程中最慢的

00:02:20.444 --> 00:02:26.424
而且如果有个同事用的是 Python 2 但是你的程序是用 Python 3 写的呢

00:02:26.425 --> 00:02:28.175
这样你的代码就会报错了

00:02:28.175 --> 00:02:30.530
或者另外一个同事太忙了

00:02:30.530 --> 00:02:33.500
多等了 20 分钟才开始跑程序

00:02:33.500 --> 00:02:36.039
即使你有了 11 个月的数据

00:02:36.039 --> 00:02:40.454
你也只能等第 12 个月的数据结果才能知道谁是最受欢迎的歌手

00:02:40.455 --> 00:02:44.740
当你用 Spark 这样的分布式系统时就会遇到上面的问题了

00:02:44.740 --> 00:02:48.385
这个例子里我们直接用 Python 就行了 

00:02:48.384 --> 00:02:50.245
所以根据我们的定义

00:02:50.245 --> 00:02:52.400
你的数据不能叫做大数据

