WEBVTT
Kind: captions
Language: zh-CN

00:00:07.519 --> 00:00:10.949
当我们讨论分布式计算时

00:00:10.949 --> 00:00:13.859
我们通常说的是超大的计算任务

00:00:13.859 --> 00:00:16.439
通常要通过节点集群来计算

00:00:16.440 --> 00:00:21.225
每个节点都要处理部分的数据

00:00:21.225 --> 00:00:26.595
最后我们把这些处理后的结果合并得到最后结果

00:00:26.594 --> 00:00:31.335
但是这些节点是如何知道以什么顺序去跑哪些任务呢？

00:00:31.335 --> 00:00:33.045
所有的节点都一样吗？

00:00:33.045 --> 00:00:37.189
当你跑代码时 你用的是哪台机器？

00:00:37.189 --> 00:00:42.289
计算框架以 Master-Worker 模式为主

00:00:42.289 --> 00:00:47.869
其中主节点负责分配任务

00:00:47.869 --> 00:00:52.369
工作节点负责执行计算

00:00:52.369 --> 00:00:55.789
 Spark有四种设置模式

00:00:55.789 --> 00:00:58.054
第一种模式是单机模式

00:00:58.054 --> 00:01:01.100
在这种模式下 所有的计算都发生在一台电脑中

00:01:01.100 --> 00:01:03.304
虽然我们在使用 Spark的 API

00:01:03.304 --> 00:01:06.275
但我们并没有做任何的分布式计算

00:01:06.275 --> 00:01:11.255
单机模式对于学习语法和搭建项目雏形很有帮助

00:01:11.254 --> 00:01:15.310
在第二节课里你会在单机模式下进行操作

00:01:15.310 --> 00:01:19.754
通过教室的工作空间 (Workspace)去学习 Spark 的语法

00:01:19.754 --> 00:01:24.439
另外三种模式都是需要集群管理器的分布式模式

00:01:24.439 --> 00:01:29.524
集群管理器单独用来管理资源的

00:01:29.525 --> 00:01:34.085
同时确保所有的机器运行任务时能及时响应

00:01:34.084 --> 00:01:37.640
集群管理器有三种选项

00:01:37.640 --> 00:01:40.715
Spark 自带的 独立集群管理器

00:01:40.715 --> 00:01:43.280
来自 Hadoop项目 的 YARN

00:01:43.280 --> 00:01:49.314
和来自 UC Berkeley 的 AMPLab 的开源管理器

00:01:49.314 --> 00:01:53.700
YARN 在需要和别人分享集群时 会非常有帮助 

00:01:53.700 --> 00:01:56.085
目前 我们不涉及这种情况

00:01:56.084 --> 00:01:59.029
在第三节课里

00:01:59.030 --> 00:02:04.135
你会用 Standalone 模式搭建自己分布式 Spark 集群

00:02:04.135 --> 00:02:08.280
在 Spark 的 Standalone 中 我们还有一个所谓的驱动程序 

00:02:08.280 --> 00:02:10.180
如果你打开一个 Spark shell

00:02:10.180 --> 00:02:12.085
随便是 Python 或者 Scala,

00:02:12.085 --> 00:02:14.974
你会和这个驱动程序直接进行交互

00:02:14.974 --> 00:02:19.335
它扮演着 Marster 的角色 

00:02:19.335 --> 00:02:22.270
负责给执行者分配任务

