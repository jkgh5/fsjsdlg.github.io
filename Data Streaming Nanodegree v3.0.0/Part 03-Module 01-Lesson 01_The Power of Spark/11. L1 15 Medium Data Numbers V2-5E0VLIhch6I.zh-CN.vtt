WEBVTT
Kind: captions
Language: zh-CN

00:00:06.450 --> 00:00:08.919
太好了

00:00:08.919 --> 00:00:12.224
你征用同事们的电脑做了个临时的分布式集群

00:00:12.224 --> 00:00:14.169
但别忘了重点

00:00:14.169 --> 00:00:17.964
你要找到加拿大用户最喜爱的歌手

00:00:17.964 --> 00:00:20.530
目前为止 我们已经把

00:00:20.530 --> 00:00:24.175
非加拿大用户剔除并且提取出了歌手的名字

00:00:24.175 --> 00:00:27.070
我们还要把每个歌手的出现次数加总

00:00:27.070 --> 00:00:30.490
然后排序找到最受欢迎的歌手

00:00:30.489 --> 00:00:33.004
因为你只要歌手的名字

00:00:33.005 --> 00:00:35.955
而考虑到加拿大的用户数量也只占总用户量的一小部分

00:00:35.954 --> 00:00:41.359
所以最终你同事返回的数据加起来只有 10 个G

00:00:41.359 --> 00:00:44.630
当然你的内存无法一次容纳这么多数据

00:00:44.630 --> 00:00:47.655
所以这仍算大数据

00:00:47.655 --> 00:00:51.079
但实际上 你用一台电脑来处理会更加方便

00:00:51.079 --> 00:00:55.049
虽然需要超过 10 G 的内存来给歌手排序

00:00:55.049 --> 00:00:57.729
毕竟排序是个超线性的算法

00:00:57.729 --> 00:01:01.904
但是这个问题并不需要我们给 10 G 的数据都排序

00:01:01.905 --> 00:01:05.165
我们可以写个程序先把每个歌手的出现次数

00:01:05.165 --> 00:01:09.680
加总得到每个歌手出现总数的数据

00:01:09.680 --> 00:01:12.310
这样我们就不用处理数百万的数据了

00:01:12.310 --> 00:01:14.260
只需要处理加总后的歌手数据

00:01:14.260 --> 00:01:17.060
或许只有几千个歌手呢

00:01:17.060 --> 00:01:18.950
也就小几千字节吧

00:01:18.950 --> 00:01:21.465
当我们得到了这个中间结果时

00:01:21.465 --> 00:01:24.590
就可以用电脑的内存来做排序了

00:01:24.590 --> 00:01:27.140
但我们如何得到这个中间结果呢

00:01:27.140 --> 00:01:31.150
一个小窍门就是先写个简单的小程序

00:01:31.150 --> 00:01:35.280
把名字从 A 到 M 开头的歌手单独成组

00:01:35.280 --> 00:01:38.269
剩下的歌手为另一组

00:01:38.269 --> 00:01:41.280
结束之后 你就可以把每组数据读取到内存里

00:01:41.280 --> 00:01:43.400
大概 5 个 G 吧

00:01:43.400 --> 00:01:47.425
然后对每个歌手的出现次数加总

00:01:47.424 --> 00:01:51.920
当数据集大于内存时 我们会不自觉的认为

00:01:51.920 --> 00:01:53.795
这就是大数据

00:01:53.795 --> 00:01:57.165
但是这个例子告诉我们 情况往往不那么简单

00:01:57.165 --> 00:01:59.140
这也不一定是大数据

00:01:59.140 --> 00:02:01.000
有时你的数据比较小

00:02:01.000 --> 00:02:02.855
或许只有 2 G

00:02:02.855 --> 00:02:04.840
但是你需要做一些非常复杂的运算

00:02:04.840 --> 00:02:06.965
比如训练一个深度学习模型

00:02:06.965 --> 00:02:09.509
或许多些硬件会更好

00:02:09.509 --> 00:02:11.965
这也可以说是大数据

00:02:11.965 --> 00:02:15.360
所以说大数据没有简单明了的定义

00:02:15.360 --> 00:02:18.350
但是只要你清楚你电脑的性能

00:02:18.349 --> 00:02:23.079
你就知道什么时候是大数据以及什么时候该用 Spark 了

