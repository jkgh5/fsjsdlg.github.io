WEBVTT
Kind: captions
Language: zh-CN

00:00:07.339 --> 00:00:13.480
尽管分布式计算和大数据应用已经存在很久了

00:00:13.480 --> 00:00:16.105
绝大多数人仍会认为最近的大数据潮与

00:00:16.105 --> 00:00:18.935
Hadoop 生态系统的出现有关

00:00:18.934 --> 00:00:22.299
我们先来了解 Hadoop 的主要构成

00:00:22.300 --> 00:00:25.734
然后讲些相关技术

00:00:25.734 --> 00:00:28.379
但就像 David 刚开始提到的那样

00:00:28.379 --> 00:00:31.809
整个生态系统非常复杂 

00:00:31.809 --> 00:00:35.560
你并不需要了解所有知识来学习 Spark

00:00:35.560 --> 00:00:40.359
Hadoop 开源框架是由Doug Cutting 和 Mike Cafarella 在2006 年共同搭建的

00:00:40.359 --> 00:00:46.000
该框架来源于 Google 在 2000 年初发表的论文 

00:00:46.000 --> 00:00:49.744
Hadoop 框架包括  4 个主要部分

00:00:49.744 --> 00:00:54.524
第一部分是 Hadoop 分布式文件系统 简称 HDFS

00:00:54.524 --> 00:00:58.554
HDFS  把数据存储在带应用程序的商用机集群上

00:00:58.554 --> 00:01:02.215
这样系统可以给整个集群提供非常高的总体带宽

00:01:02.215 --> 00:01:06.140
第二部分, Hadoop MapReduce  

00:01:06.140 --> 00:01:10.234
是一个MapReduce 编程模型在处理大规模数据的应用程序

00:01:10.234 --> 00:01:12.049
绝大多数人提到 MapReduce 时

00:01:12.049 --> 00:01:13.849
指的就是这个

00:01:13.849 --> 00:01:17.329
第三部分是个叫做 Hadoop YARN  的资源管理器

00:01:17.329 --> 00:01:21.314
它会负责为用户程序调度运算资源

00:01:21.314 --> 00:01:28.640
最后一部分是 Hadoop Common  它包含了Hadoop其他组件需要的工具和库

00:01:28.640 --> 00:01:31.840
MapReduce 项目刚开始不久

00:01:31.840 --> 00:01:37.704
其他项目就开始用这个 Java 框架搭建更高级的东西

00:01:37.704 --> 00:01:39.700
比如Apache Pig 

00:01:39.700 --> 00:01:43.155
就是由 Yahoo开发的一个平台 

00:01:43.155 --> 00:01:47.859
研究者可以用类似 SQL 的语言在平台上跑 MapReduce 任务

00:01:47.859 --> 00:01:51.484
Apache Hive 是另一个

00:01:51.484 --> 00:01:57.314
提供用 SQL 做数据总结、查询和分析的高级界面

00:01:57.314 --> 00:02:02.030
传统 MapReduce 方法有个问题 

00:02:02.030 --> 00:02:04.340
每一步之后的结果都存在了硬盘中

00:02:04.340 --> 00:02:06.900
如果你还记得上一个视频

00:02:06.900 --> 00:02:09.189
硬盘非常慢

00:02:09.189 --> 00:02:11.560
所以这个过程就会非常耗时

00:02:11.560 --> 00:02:15.545
这就促使了Matei Zaharia 于 2009年

00:02:15.544 --> 00:02:20.089
开始在 UC Berkeley 的 AmpLab 做 disbarred 项目 

00:02:20.090 --> 00:02:24.680
Spark 不用把中间结果写入硬盘 

00:02:24.680 --> 00:02:29.495
在Map 和 Reduce 的过程都可以在内存中完成

00:02:29.495 --> 00:02:36.770
这个项目在2010年开源 而后在2014年成为了一个顶级 Apache 项目 

00:02:36.770 --> 00:02:41.930
从那以后 其流行度和适应性与日俱增

00:02:41.930 --> 00:02:44.360
还有另外两种分布式计算流

00:02:44.360 --> 00:02:48.200
差不多和 Spark 同时进行

00:02:48.199 --> 00:02:52.879
后来变成了顶级 Apache 项目 Storm 和 Flink

00:02:52.879 --> 00:02:55.814
Storm 是Nathan Marz 开发的

00:02:55.814 --> 00:02:59.484
当时他在一家叫BackType 的创业公司工作

00:02:59.485 --> 00:03:03.010
Twitter 后来收购了BackType 并将Storm开源了

00:03:03.009 --> 00:03:08.823
Flink 始于德国高校和研究机构的合作

00:03:08.824 --> 00:03:11.835
两个工具都是为了高速计算数据流

00:03:11.835 --> 00:03:14.120
你可以在毫秒级时间内获取结果

00:03:14.120 --> 00:03:18.730
这个方式比 Spark的数据流计算库要快的多

