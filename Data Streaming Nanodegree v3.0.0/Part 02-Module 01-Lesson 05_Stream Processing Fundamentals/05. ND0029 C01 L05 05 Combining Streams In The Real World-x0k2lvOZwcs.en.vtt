WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.730
There are many examples of where we might want to

00:00:02.730 --> 00:00:05.445
join streams in a stream processing application.

00:00:05.445 --> 00:00:09.810
A simple example might involve a company with operations in many regions.

00:00:09.810 --> 00:00:13.260
Let's pretend that we work for a shipping or distribution company.

00:00:13.259 --> 00:00:16.079
We might have data streams of purchases split by

00:00:16.079 --> 00:00:18.959
region based on where the various data centers are located.

00:00:18.960 --> 00:00:21.780
Using a streaming join, we can pull all the data from

00:00:21.780 --> 00:00:25.380
the various regions together in real-time for higher-level analytics.

00:00:25.379 --> 00:00:28.184
So in this example, I've chosen Germany,

00:00:28.184 --> 00:00:31.539
China, and India all with their own separate data streams,

00:00:31.539 --> 00:00:35.670
and they're piped through Kafka and then our stream processors subscribes to

00:00:35.670 --> 00:00:38.715
all three topics and then joins

00:00:38.715 --> 00:00:42.420
all three of those streams together into one output stream.

00:00:42.420 --> 00:00:45.530
Another example may involve real-time pricing.

00:00:45.530 --> 00:00:47.929
Say we worked at a rideshare company and we wanted to

00:00:47.929 --> 00:00:50.600
consider it lowering or raising the price based not

00:00:50.600 --> 00:00:55.804
just on demand but also other factors such as weather or outages and public transit.

00:00:55.804 --> 00:00:58.100
If we joined a real-time aggregative demand for

00:00:58.100 --> 00:01:01.310
a given time window with weather events and public transit status,

00:01:01.310 --> 00:01:04.954
we could emit events that indicate the current state of demand in our system.

00:01:04.954 --> 00:01:06.980
The critical difference in these scenarios

00:01:06.980 --> 00:01:09.469
relative traditional batch processing approaches is

00:01:09.469 --> 00:01:14.105
that these calculations run continually and not on a specifically scheduled basis.

00:01:14.105 --> 00:01:17.975
So again, in this example which we saw as well in the first lesson,

00:01:17.974 --> 00:01:19.884
we're taking data about events,

00:01:19.885 --> 00:01:21.630
weather, and user data.

00:01:21.629 --> 00:01:24.170
Then we have a downstream stream processing application

00:01:24.170 --> 00:01:26.090
that's combining this information into

00:01:26.090 --> 00:01:28.670
one output event which indicates whether demand

00:01:28.670 --> 00:01:32.400
is going up or down and how that should impact price.

