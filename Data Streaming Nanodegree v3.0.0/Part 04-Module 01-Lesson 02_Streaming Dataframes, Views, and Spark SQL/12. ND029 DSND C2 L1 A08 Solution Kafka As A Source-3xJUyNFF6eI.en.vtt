WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.800
Let's look at the solution to exercise 2 where we're going

00:00:04.800 --> 00:00:10.170
to be pulling in data about a ATM visit topic from kafka.

00:00:10.170 --> 00:00:12.630
The first thing I need to do is to start kafka.

00:00:12.630 --> 00:00:15.135
I'm going to click this button.

00:00:15.135 --> 00:00:18.210
I'm watching a spinning cursor down here.

00:00:18.210 --> 00:00:20.655
That tells me it's in progress,

00:00:20.655 --> 00:00:24.150
zookeeper is up, now, we're starting kafka.

00:00:24.150 --> 00:00:29.280
Zookeeper is not needed for spark but it is needed for kafka.

00:00:29.280 --> 00:00:32.520
We're still starting. That's what the little spinner is telling us.

00:00:32.520 --> 00:00:35.710
While that's happening, I'm going to start up spark.

00:00:35.780 --> 00:00:41.175
I've got the log file location copied from that.

00:00:41.175 --> 00:00:49.810
I cut that file and it's done so I'm in a tail it and just watch it as it goes.

00:00:49.810 --> 00:00:52.785
The master is still starting.

00:00:52.785 --> 00:00:55.440
This is a normal message,

00:00:55.440 --> 00:01:02.425
it happens pretty much every time but it still is able to run using the built-in classes.

00:01:02.425 --> 00:01:04.970
Now, we've got our Spark URI,

00:01:04.970 --> 00:01:06.965
where the master is reachable.

00:01:06.965 --> 00:01:11.195
I'm going to copy that and them I'm going to control C to break out of tail.

00:01:11.195 --> 00:01:20.555
Go to homework space spark sbin and start the worker and I've passed in the master URI,

00:01:20.555 --> 00:01:23.135
if I say ps-ef.

00:01:23.135 --> 00:01:27.485
Here I have multiple Java processes.

00:01:27.485 --> 00:01:32.700
One of them is running spark, two of them are.

00:01:32.700 --> 00:01:34.960
Let's repeat that.

00:01:35.090 --> 00:01:37.685
This one here and this one,

00:01:37.685 --> 00:01:39.635
if you could see beyond the terminal,

00:01:39.635 --> 00:01:41.000
normally when you expand it,

00:01:41.000 --> 00:01:43.040
you can see further to the right.

00:01:43.040 --> 00:01:46.910
What you'll see beyond this java-8-open jdk-md6 is

00:01:46.910 --> 00:01:50.720
the word spark further on to the right and when you see that on each of these,

00:01:50.720 --> 00:01:52.110
that tells you, hey,

00:01:52.110 --> 00:01:54.585
I've got spark running, there's spark in the path.

00:01:54.585 --> 00:01:58.060
If you see one and two that's master and worker,

00:01:58.060 --> 00:01:59.200
it doesn't matter which is which,

00:01:59.200 --> 00:02:01.110
the fact is you've got both of them running.

00:02:01.110 --> 00:02:05.360
The time may help you know which one because this is earlier than the other.

00:02:05.360 --> 00:02:07.655
That's my master and that's the worker.

00:02:07.655 --> 00:02:11.260
Going back to kafka, it looks like kafka is up and running.

00:02:11.260 --> 00:02:13.355
Looking through the entries here,

00:02:13.355 --> 00:02:17.900
you will see where it says that kafka started up successfully.

00:02:17.900 --> 00:02:19.790
Kafka connect started as well,

00:02:19.790 --> 00:02:24.825
which is pretty much the last step there so we're good to go.

00:02:24.825 --> 00:02:27.920
Now, let's write the solution for this.

00:02:27.920 --> 00:02:31.835
We've got our spark session imported so we're going to start by creating

00:02:31.835 --> 00:02:36.450
a session and we're subscribing to the ATM visits topic.

00:02:36.450 --> 00:02:39.710
I'm just going to name the application the same thing.

00:02:39.710 --> 00:02:43.780
The only place you see that is when you're looking at logging for spark,

00:02:43.780 --> 00:02:46.130
you're going to see that ATM visits show up.

00:02:46.130 --> 00:02:50.635
That's the name of the application that it'll refer to later on.

00:02:50.635 --> 00:02:53.025
Setting the log level,

00:02:53.025 --> 00:02:55.515
now I'm going to read from kafka.

00:02:55.515 --> 00:02:58.050
When I do that I get a data frame.

00:02:58.050 --> 00:02:59.405
That's the result.

00:02:59.405 --> 00:03:04.720
I am going to name the data frame something important that helps me remember what it is.

00:03:04.720 --> 00:03:07.855
I'm calling this atmVisitsRawStreamingDataFrame.

00:03:07.855 --> 00:03:11.880
Now I'm going to access the spark session and go to

00:03:11.880 --> 00:03:15.945
the read stream where we can now access kafka.

00:03:15.945 --> 00:03:18.710
We're going to say the format is kafka and that's when it

00:03:18.710 --> 00:03:22.075
tells it to access the libraries that we've used.

00:03:22.075 --> 00:03:27.925
They're special kafka libraries for spark to use and connecting with kafka.

00:03:27.925 --> 00:03:31.145
Here's where we tell it the name of the server.

00:03:31.145 --> 00:03:35.200
In our case, it's just local host with a port of 9092.

00:03:35.200 --> 00:03:38.120
I'm going to subscribe to the topic and this is

00:03:38.120 --> 00:03:40.530
where I actually need this to say ATM visits.

00:03:40.530 --> 00:03:43.190
The application name doesn't matter very much.

00:03:43.190 --> 00:03:46.930
Here it matters a lot that this is the right topic name.

00:03:46.930 --> 00:03:49.640
We're going to tell it to read all the data that it can

00:03:49.640 --> 00:03:51.815
find in kafka for this topic by saying

00:03:51.815 --> 00:03:57.410
earliest rather than latest and then we're going to tell it to load that data frame.

00:03:57.410 --> 00:04:02.570
The resulting data frame has raw binary data and we want to

00:04:02.570 --> 00:04:08.040
convert that so I'm going to copy it to another data frame that's not binary.

00:04:08.040 --> 00:04:11.830
That one I just called it atmVisitsStreamingDF.

00:04:11.830 --> 00:04:15.440
Here I'm going to go ahead and cast the key from Kafka as

00:04:15.440 --> 00:04:21.245
a string and the key for that is going to be the transaction ID.

00:04:21.245 --> 00:04:23.735
I'm just going to call it transactionID.

00:04:23.735 --> 00:04:26.270
You could just call it key if you wanted to but

00:04:26.270 --> 00:04:29.030
it makes it more meaningful to give it a good name.

00:04:29.030 --> 00:04:35.610
I'm going to cast the value as a string as well and this is the ATM location.

00:04:35.610 --> 00:04:40.075
That's the value we're getting from kafka in this case.

00:04:40.075 --> 00:04:48.190
Next, I want to go ahead and select everything into the console.

00:04:48.190 --> 00:04:54.250
Let's do that, atmVisitsStreamingDF.writeStream.outputMode.

00:04:56.000 --> 00:05:00.180
We're going to tell it to append as we go.

00:05:00.180 --> 00:05:03.540
We want to append to the console.

00:05:03.540 --> 00:05:05.670
We're going to tell it to start,

00:05:05.670 --> 00:05:08.250
that starts the whole application

00:05:08.250 --> 00:05:12.660
and we're going to tell it to run until it's told to stop.

00:05:12.660 --> 00:05:16.875
I'm going ahead and save that python file.

00:05:16.875 --> 00:05:19.715
Then we've got a script for us.

00:05:19.715 --> 00:05:26.130
If we do LS we'll see submit-kafkaconsole.sh and run that script.

00:05:26.130 --> 00:05:27.470
That just tells it,

00:05:27.470 --> 00:05:30.980
then the libraries it makes it a little easier to give it the command

00:05:30.980 --> 00:05:35.640
but you can run it by hand if you prefer but I'm going to run the script this time.

00:05:38.150 --> 00:05:40.605
We have an error.

00:05:40.605 --> 00:05:46.530
It says no such file or directory as kafkaconsole.py.

00:05:47.420 --> 00:05:58.695
It's saying that the command is incorrect so I'm going to go and I opened that script

00:05:58.695 --> 00:06:03.930
and it's saying home workspace

00:06:03.930 --> 00:06:08.420
kafkaconsole.py and I'm just going to run

00:06:08.420 --> 00:06:13.360
this command by hand just to see if the error goes away.

00:06:13.360 --> 00:06:17.595
It still says that file doesn't exist.

00:06:17.595 --> 00:06:26.955
If I LS, kafkaconsole.py is a file, there's a typo.

00:06:26.955 --> 00:06:34.365
The F is in the wrong place so I'm going to rename that. There we go.

00:06:34.365 --> 00:06:38.025
Now and just paste it in that same command

00:06:38.025 --> 00:06:42.670
and it's loading a bunch of Java libraries to get everything started.

00:06:42.670 --> 00:06:47.065
Now it's saying online nine.

00:06:47.065 --> 00:06:49.820
There's an error.

00:06:49.970 --> 00:06:56.230
Format is incorrect so we're going to save that.

00:06:58.250 --> 00:07:09.750
It says atmVisitsRawStreamingDF is not defined and that's because there's a typo.

00:07:09.750 --> 00:07:12.670
I'm going to save that.

00:07:14.570 --> 00:07:20.875
I just hit up arrow and enter to repeat the same run command.

00:07:20.875 --> 00:07:24.320
When you get to this registered endpoint,

00:07:24.320 --> 00:07:25.760
that tells us we're waiting for

00:07:25.760 --> 00:07:30.515
the output so the blinking cursor says it's still running.

00:07:30.515 --> 00:07:34.745
Now, we've got some ATM visits so here's a transaction in the Philippines,

00:07:34.745 --> 00:07:37.010
here's one in India, one in Ghana,

00:07:37.010 --> 00:07:39.980
another in Ghana for a completely different charge.

00:07:39.980 --> 00:07:41.690
One in Uganda, France,

00:07:41.690 --> 00:07:44.080
New Mexico, South Africa.

00:07:44.080 --> 00:07:48.180
There's our transaction ID and there's our location.

00:07:48.180 --> 00:07:51.050
If you got this working, congratulations,

00:07:51.050 --> 00:07:55.960
this is not easy when you're new to spark and kafka both at the same time.

00:07:55.960 --> 00:07:59.980
I'm going to kill this and then we're done.

