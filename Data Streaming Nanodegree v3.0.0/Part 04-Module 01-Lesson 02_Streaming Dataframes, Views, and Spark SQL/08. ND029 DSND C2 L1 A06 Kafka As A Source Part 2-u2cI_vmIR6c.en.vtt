WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.610
You just learned about Spark DataFrames.

00:00:02.610 --> 00:00:06.600
Next, you will learn how to read a DataFrame from a Kafka source.

00:00:06.600 --> 00:00:08.490
To construct a Kafka stream,

00:00:08.490 --> 00:00:10.140
you first provide a broker name,

00:00:10.140 --> 00:00:11.910
then you choose a topic.

00:00:11.910 --> 00:00:15.795
Last, you should indicate if you want earliest or latest messages.

00:00:15.795 --> 00:00:20.310
Earliest means you would like to read your messages starting with the oldest ones.

00:00:20.310 --> 00:00:23.715
Latest means you'd like to read the most recent messages first.

00:00:23.715 --> 00:00:26.055
This option doesn't read the older messages,

00:00:26.055 --> 00:00:29.295
just those from the time the stream starts going forward.

00:00:29.295 --> 00:00:34.260
Here's a Spark streaming application using a Kafka stream as a source.

00:00:34.260 --> 00:00:38.580
Our source DataFrame, in this example called KafkaRawStreamingDF,

00:00:38.580 --> 00:00:41.115
is created by reading from a read stream.

00:00:41.115 --> 00:00:45.940
We chain the option function to provide multiple connection parameters.

00:00:45.940 --> 00:00:50.675
The first parameter we pass is the kafka.bootstrap.servers parameter.

00:00:50.675 --> 00:00:52.190
This is our broker.

00:00:52.190 --> 00:00:55.415
The next parameter we pass is the subscribe parameter.

00:00:55.415 --> 00:00:57.070
This is the topic.

00:00:57.070 --> 00:01:01.010
The last parameter we send is the startingOffsets parameter.

00:01:01.010 --> 00:01:03.680
This tells Kafka we want messages starting at

00:01:03.680 --> 00:01:06.350
the earliest message it received for the topic.

00:01:06.350 --> 00:01:09.325
Keep in mind that messages do expire eventually.

00:01:09.325 --> 00:01:13.955
Earliest is actually the earliest message Kafka still remembers.

00:01:13.955 --> 00:01:16.130
In a Kafka configuration,

00:01:16.130 --> 00:01:21.500
a broker is the server to which requests from external systems can be addressed.

00:01:21.500 --> 00:01:25.970
Also, the central processing component of a Kafka cluster.

00:01:25.970 --> 00:01:28.340
In a Kafka configuration,

00:01:28.340 --> 00:01:31.055
a topic is a channel of communication,

00:01:31.055 --> 00:01:34.190
often representing similar or related data,

00:01:34.190 --> 00:01:36.550
sometimes called the mailbox.

00:01:36.550 --> 00:01:39.065
In a Kafka configuration,

00:01:39.065 --> 00:01:44.090
the offset is a value which determines the mode of consumption of a topic.

00:01:44.090 --> 00:01:46.685
Earliest starts at the oldest message,

00:01:46.685 --> 00:01:49.750
latest starts at the newest message.

00:01:49.750 --> 00:01:54.695
Have you ever known someone who can intelligently discuss just about anything?

00:01:54.695 --> 00:01:57.530
It doesn't seem to matter what the conversation is about,

00:01:57.530 --> 00:01:59.645
they just happen to know something about it.

00:01:59.645 --> 00:02:01.625
Kafka has a similar quality.

00:02:01.625 --> 00:02:05.465
It can describe details about dozens or hundreds of topics.

00:02:05.465 --> 00:02:09.425
Each topic can come from one to many other data sources.

00:02:09.425 --> 00:02:12.485
You just learned how to read from a Kafka source.

00:02:12.485 --> 00:02:16.840
Next, we will discuss Kafka keys and Kafka values.

00:02:16.840 --> 00:02:20.675
Every message you read from Kafka has two fields.

00:02:20.675 --> 00:02:24.140
The key column is like the primary key for a database table,

00:02:24.140 --> 00:02:26.750
and is often a unique identifier.

00:02:26.750 --> 00:02:30.785
The value column contains the bulk of the data being transmitted.

00:02:30.785 --> 00:02:35.575
By default, the Kafka key and value are in binary format.

00:02:35.575 --> 00:02:38.884
You just learned about Kafka keys and values.

00:02:38.884 --> 00:02:42.850
Next, you will learn how to cast data using data types.

00:02:42.850 --> 00:02:45.304
Just as in a relational database,

00:02:45.304 --> 00:02:48.410
Spark streaming DataFrame support typed data.

00:02:48.410 --> 00:02:51.665
Since Kafka messages are binary by default,

00:02:51.665 --> 00:02:56.035
in this example we have binary for a person's name, Peyton.

00:02:56.035 --> 00:03:02.650
You want to cast them as strings using the cast function inside of the select expression.

00:03:02.650 --> 00:03:04.130
You will do this using

00:03:04.130 --> 00:03:09.005
the select expression function on the DataFrame containing binary data.

00:03:09.005 --> 00:03:13.500
In this example, you see the result which is Peyton.

